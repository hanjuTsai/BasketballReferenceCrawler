{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "from selenium import webdriver\n",
    "from IPython.display import clear_output\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreigner(html):\n",
    "    soup = BeautifulSoup(html,'html.parser',from_encoding='utf-8')\n",
    "    links = soup.find_all('p')\n",
    "    # print(links)\n",
    "    # <span itemprop=\"birthPlace\">\n",
    "\n",
    "    links = soup.find_all(['span'] , attrs = { 'itemprop' : 'birthPlace'})\n",
    "    for link in links:\n",
    "        for c in (link.descendants):\n",
    "            aa = ((c.find_next('a')).attrs)\n",
    "            if 'country=US' in aa['href']:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should exccute the chromedriver and get the page source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def league(html):\n",
    "    result = []\n",
    "    soup = BeautifulSoup(html,'html.parser',from_encoding='utf-8')\n",
    "    links = soup.find_all('div', attrs = {'class': 'leaderboard_wrapper' , 'id': 'all_leaderboard'})\n",
    "\n",
    "    comments = soup.findAll(text=lambda text:isinstance(text, Comment))\n",
    "    for comment in comments:\n",
    "        a = comment.find('div_leaderboard')\n",
    "        if (a != -1):\n",
    "            #print(a,comment)\n",
    "            break\n",
    "            \n",
    "    ts = BeautifulSoup(comment.string, 'html.parser')\n",
    "    ts = ts.find_all('div', {'id' : 'leaderboard_all_league' , 'class' : 'data_grid_box'})\n",
    "    for tt in ts:\n",
    "        kk = tt.table.find_all('a')\n",
    "        for k in kk:\n",
    "            result.append((k.text))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should exceute the chromedriver and get the page source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allstar(html):\n",
    "    result = []\n",
    "    soup = BeautifulSoup(html,'html.parser',from_encoding='utf-8')\n",
    "    links = soup.find_all('div', attrs = {'class': 'leaderboard_wrapper' , 'id': 'all_leaderboard'})\n",
    "\n",
    "    comments = soup.findAll(text=lambda text:isinstance(text, Comment))\n",
    "    for comment in comments:\n",
    "        a = comment.find('div_leaderboard')\n",
    "        if (a != -1):\n",
    "            #print(a,comment)\n",
    "            break\n",
    "    ts = BeautifulSoup(comment.string, 'html.parser')\n",
    "    ts = ts.find_all('div', {'id' : 'leaderboard_allstar' , 'class' : 'data_grid_box'})\n",
    "    for tt in ts:\n",
    "        kk = tt.table.find_all('a')\n",
    "        for k in kk:\n",
    "            result.append((k.text))\n",
    "            \n",
    "    result = list(map (lambda x : str(int(x.split()[0])-1 ) + '-' + (x.split()[0][2:])  , result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hall(html):\n",
    "    soup = BeautifulSoup(html,'html.parser',from_encoding='utf-8')\n",
    "    links = soup.find_all('li' , {'class'  : 'bling_special bling_hof'})\n",
    "    for link in links:\n",
    "        if link.text == \"Hall of Fame\":\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def btn_click(wd,url):\n",
    "    wd.get(url)\n",
    "    script = \"vjs_addClass(document.getElementById('leaderboard_allstar'),'show_all')\"\n",
    "    script2 = \"vjs_addClass(document.getElementById('leaderboard_allleague'),'show_all')\"\n",
    "    btn = wd.execute_script(script)\n",
    "    btn = wd.execute_script(script2)\n",
    "    return(wd.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_info(wd,url):\n",
    "    html = btn_click(wd,url)\n",
    "    result = ([Hall(html) ,league(html), allstar(html), foreigner(html)])\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "df = pd.read_csv('./info/player_my_df.csv')\n",
    "info = pd.read_excel('./info/info.xlsx')\n",
    "\n",
    "dirs = !ls ./data\n",
    "dirs_no = sorted(list(map (lambda x : int(x.split('.')[0]),dirs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_game_table(html):\n",
    "    \n",
    "    soup = BeautifulSoup(html,'html.parser',from_encoding='utf-8')    \n",
    "    links = soup.find_all('table', { 'id' : 'per_game'} )\n",
    "    \n",
    "    ## Cannot find the all per game table\n",
    "    if (len(links) == 0):\n",
    "        return\n",
    "\n",
    "    rows = links[0].find_all('tr')\n",
    "\n",
    "    colname = []\n",
    "    rowname = []\n",
    "    for header in links[0].find_all('th', {'scope' : 'col'}):\n",
    "        colname.append(header.text)\n",
    "        \n",
    "    for header in links[0].find_all('th', {'scope' : 'row'}):\n",
    "        rowname.append(header.text)\n",
    "        \n",
    "    table =[]\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    rnum = 0\n",
    "    for row in links[0].find_all('tr'):\n",
    "        table = []\n",
    "        columns = row.find_all('td')\n",
    "        \n",
    "        for column in columns:\n",
    "            ex = column.text.split('-')\n",
    "            try:\n",
    "                if len(ex) > 1 and int(ex[0]):\n",
    "                    rowname.insert(rnum, column.text)\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "            table.append(column.text)\n",
    "        \n",
    "        ## The table is NA \n",
    "        if not table :\n",
    "            continue   \n",
    "            \n",
    "        rnum = rnum + 1    \n",
    "        df = df.append(pd.Series(table),ignore_index=True)\n",
    "    \n",
    "    df[colname[0]] = pd.Series(rowname)\n",
    "    df.columns = colname[-len(colname) + 1 :] + colname[:-len(colname) + 1 ]\n",
    "    return(df[colname])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the all data processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/bs4/__init__.py:179: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Season Age   Tm   Lg Pos     G   GS    MP   FG   FGA ...  呎  吋    磅  \\\n",
      "0   1985-86  22  LAL  NBA  PF    82    1  18.8  2.5   4.7 ...  6  9  220   \n",
      "1   1986-87  23  LAL  NBA  PF    79   72  28.4  4.0   7.4 ...  6  9  220   \n",
      "2   1987-88  24  LAL  NBA  PF    82   64  32.1  3.9   7.8 ...  6  9  220   \n",
      "3   1988-89  25  LAL  NBA  PF    82   82  30.6  4.9   9.2 ...  6  9  220   \n",
      "4   1989-90  26  LAL  NBA  PF    82   82  33.0  4.7   9.8 ...  6  9  220   \n",
      "5   1990-91  27  LAL  NBA  PF    82   21  26.4  3.1   6.6 ...  6  9  220   \n",
      "6   1991-92  28  LAL  NBA  PF    82   53  35.4  4.7   9.8 ...  6  9  220   \n",
      "7   1992-93  29  LAL  NBA  PF    82   55  34.4  4.6   8.6 ...  6  9  220   \n",
      "8   1993-94  30  PHO  NBA  PF    82   55  34.5  5.7  11.3 ...  6  9  220   \n",
      "9   1994-95  31  PHO  NBA  SF    82   52  32.8  3.8   7.5 ...  6  9  220   \n",
      "10  1995-96  32  PHO  NBA  SF    82   36  25.8  2.6   5.4 ...  6  9  220   \n",
      "11  1996-97  33  TOT  NBA  PF    83   73  30.0  2.8   5.8 ...  6  9  220   \n",
      "12  1996-97  33  PHO  NBA  PF    27   19  20.3  2.3   4.7 ...  6  9  220   \n",
      "13  1996-97  33  DAL  NBA  PF    56   54  34.7  3.1   6.4 ...  6  9  220   \n",
      "14  1997-98  34  DAL  NBA  PF    82   68  32.3  3.0   6.5 ...  6  9  220   \n",
      "15  1998-99  35  DAL  NBA  PF    50   35  18.5  2.2   5.1 ...  6  9  220   \n",
      "16  1999-00  36  LAL  NBA  PF    82   82  23.5  2.1   4.7 ...  6  9  220   \n",
      "17  2000-01  37  MIA  NBA  PF    82    1  17.2  1.8   4.0 ...  6  9  220   \n",
      "18   Career           NBA      1278  832  28.6  3.6   7.2 ...  6  9  220   \n",
      "\n",
      "                   Colleges 出生月 出生日   出生年   位置.1 選秀順位  年資  \n",
      "0   Oregon State University  10   4  1963  PF-SF   23   1  \n",
      "1   Oregon State University  10   4  1963  PF-SF   23   2  \n",
      "2   Oregon State University  10   4  1963  PF-SF   23   3  \n",
      "3   Oregon State University  10   4  1963  PF-SF   23   4  \n",
      "4   Oregon State University  10   4  1963  PF-SF   23   5  \n",
      "5   Oregon State University  10   4  1963  PF-SF   23   6  \n",
      "6   Oregon State University  10   4  1963  PF-SF   23   7  \n",
      "7   Oregon State University  10   4  1963  PF-SF   23   8  \n",
      "8   Oregon State University  10   4  1963  PF-SF   23   9  \n",
      "9   Oregon State University  10   4  1963  PF-SF   23  10  \n",
      "10  Oregon State University  10   4  1963  PF-SF   23  11  \n",
      "11  Oregon State University  10   4  1963  PF-SF   23  12  \n",
      "12  Oregon State University  10   4  1963  PF-SF   23  12  \n",
      "13  Oregon State University  10   4  1963  PF-SF   23  12  \n",
      "14  Oregon State University  10   4  1963  PF-SF   23  13  \n",
      "15  Oregon State University  10   4  1963  PF-SF   23  14  \n",
      "16  Oregon State University  10   4  1963  PF-SF   23  15  \n",
      "17  Oregon State University  10   4  1963  PF-SF   23  16  \n",
      "18  Oregon State University  10   4  1963  PF-SF   23  16  \n",
      "\n",
      "[19 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# dirs = !ls ./data\n",
    "# dirs_no = sorted(list(map (lambda x : int(x.split('.')[0]),dirs)))\n",
    "\n",
    "with open ('./info/all_data', 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "      \n",
    "info = pd.read_excel('./info/info2.xlsx')\n",
    "\n",
    "col = ['Season', 'Age', 'Tm', 'Lg', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
    "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%',\n",
    "       'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "\n",
    "url = pd.read_csv('./info/player_my_df.csv')['5']\n",
    "df = pd.DataFrame(columns=col)   \n",
    "row = len(data)\n",
    "ind = info.columns\n",
    "\n",
    "for i in range(row):\n",
    "    \n",
    "    ## Request the web source\n",
    "    response = rq.get(url[i])\n",
    "    html = response.text\n",
    "    per_game_table(html) \n",
    "    my_list = per_game_table(html)\n",
    "    \n",
    "    ## The list may be null or not ##\n",
    "    if my_list is None:\n",
    "        continue\n",
    "    \n",
    "    pp = list(my_list['Season']).index('Career')\n",
    "    my_list = my_list.loc[:pp,:]\n",
    "\n",
    "    small_df = my_list\n",
    "    r , c = ((my_list.shape))\n",
    "    \n",
    "    ## Process empty column from the original table ##\n",
    "    for j in range(len(col)):\n",
    "        if col[j] not in small_df.columns:\n",
    "            small_df[col[j]] = pd.Series([' ']* r)\n",
    "    \n",
    "    ## Process fix award ##\n",
    "    ## [None, ['1988-89'], ['1989-90'], False]\n",
    "    award = data[i]\n",
    "    inf = list(info.iloc[i,:])\n",
    " \n",
    "    if(award[0]):\n",
    "        small_df['名人堂']= pd.Series([1]*r)\n",
    "    else:\n",
    "        small_df['名人堂']= pd.Series([0]*r)\n",
    "\n",
    "    if(award[3]):\n",
    "        small_df['外籍球員']= pd.Series([1]*r)\n",
    "    else:\n",
    "        small_df['外籍球員']= pd.Series([0]*r)\n",
    "\n",
    "    ## Column initialization ##\n",
    "    small_df['是否入圍全明星'] = pd.Series([0]*r)\n",
    "    small_df['當年度獎項次數'] = pd.Series([0]*r)\n",
    "    small_df['當年度獎項YN'] = pd.Series([0]*r)\n",
    "\n",
    "    ## List all season ##\n",
    "    all_series = list(small_df.iloc[:,0])\n",
    "    for m in range(len(award[2])):\n",
    "        for n in range(len(all_series)):\n",
    "            if(award[2][m] == all_series[n]):\n",
    "                small_df['是否入圍全明星'][n] = 1\n",
    "            \n",
    "    ## Count the award throught out all the career ##            \n",
    "\n",
    "    \n",
    "    for m in range(len(award[1])):\n",
    "        for n in range(len(all_series)):\n",
    "            if(award[1][m] == all_series[n]):\n",
    "                small_df['當年度獎項次數'][n] += 1\n",
    "                small_df['當年度獎項YN'][n] = 1\n",
    "                \n",
    "    small_df['當年度獎項次數'][r-1] = sum(list(small_df['當年度獎項次數']))\n",
    "\n",
    "    ## Process info fix ##\n",
    "    for k in range(len(inf)):\n",
    "        small_df[ind[k]]= pd.Series([inf[k]] * r)\n",
    "   \n",
    "    ## Process series and sort the series ##\n",
    "    year_play = pd.Series([0]*r)  \n",
    "    all_series.pop(-1)    \n",
    "    compact_id = list(set(all_series))\n",
    "    compact_id = sorted(compact_id,key= lambda x : int(x.split('-')[0]))\n",
    "   \n",
    "    ## Process the year player play ##\n",
    "    for j in range(len(all_series)):\n",
    "        front = list(small_df['Tm'])[:j]\n",
    "        count = 0 \n",
    "        \n",
    "        ## The year should minus that he didn't play\n",
    "        for k in range(len(front)):\n",
    "            if 'Did' in front[k]:\n",
    "                count += 1\n",
    "        \n",
    "        year_play[j] = compact_id.index(all_series[j]) - count + 1 \n",
    "    \n",
    "    ### The Career play year is the same as the final ##\n",
    "    year_play[j+1] = list(year_play)[-2]\n",
    "    small_df['年資'] = year_play\n",
    "    \n",
    "    ## Combine the dataframe ##\n",
    "    df = pd.concat([small_df,df],axis=0,join='outer',ignore_index=True,sort=False)\n",
    "    \n",
    "    ## Ouput ##\n",
    "    if i % 20 == 1:\n",
    "        print(i)\n",
    "\n",
    "    if i % 200 == 1:\n",
    "        clear_output()\n",
    "    print(small_df)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "cols = cols[-15:] + cols[:-15]\n",
    "cols = ['FirstName', 'LastName', 'From', 'To',\\\n",
    "        '位置', '呎', '吋', '磅', 'Colleges','出生年', '出生月', \\\n",
    "        '出生日', '選秀順位','名人堂' , '當年度獎項次數', '當年度獎項YN' , '是否入圍全明星','外籍球員', '年資', \\\n",
    "        'Season', 'Age', 'Tm', 'Lg', 'Pos', 'G', 'GS', 'MP',\\\n",
    "        'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%',\\\n",
    "        'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = df[cols]\n",
    "ss.to_excel('Helloworld.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1985-86\n",
       "1     1986-87\n",
       "2     1987-88\n",
       "3     1988-89\n",
       "4     1989-90\n",
       "5     1990-91\n",
       "6     1991-92\n",
       "7     1992-93\n",
       "8     1993-94\n",
       "9     1994-95\n",
       "10    1995-96\n",
       "11    1996-97\n",
       "12    1996-97\n",
       "13    1996-97\n",
       "14    1997-98\n",
       "15    1998-99\n",
       "16    1999-00\n",
       "17    2000-01\n",
       "18     Career\n",
       "Name: Season, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df['Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        1997-98\n",
       " 1        1998-99\n",
       " 2        1999-00\n",
       " 3        2000-01\n",
       " 4        2001-02\n",
       " 5        2002-03\n",
       " 6        2003-04\n",
       " 7        2004-05\n",
       " 8        2005-06\n",
       " 9        2006-07\n",
       " 10       2007-08\n",
       " 11       2008-09\n",
       " 12       2009-10\n",
       " 13       2010-11\n",
       " 14        Career\n",
       " 15       2003-04\n",
       " 16       2004-05\n",
       " 17       2005-06\n",
       " 18        Career\n",
       " 19       2014-15\n",
       " 20       2014-15\n",
       " 21       2014-15\n",
       " 22        Career\n",
       " 23       2017-18\n",
       " 24        Career\n",
       " 25       2000-01\n",
       " 26       2001-02\n",
       " 27       2002-03\n",
       " 28       2003-04\n",
       " 29       2004-05\n",
       "           ...   \n",
       " 33863    2016-17\n",
       " 33864     Career\n",
       " 33865    2000-01\n",
       " 33866    2001-02\n",
       " 33867    2002-03\n",
       " 33868     Career\n",
       " 33869    1990-91\n",
       " 33870    1991-92\n",
       " 33871     Career\n",
       " 33872    1999-00\n",
       " 33873     Career\n",
       " 33874    1985-86\n",
       " 33875    1986-87\n",
       " 33876    1987-88\n",
       " 33877    1988-89\n",
       " 33878    1989-90\n",
       " 33879    1990-91\n",
       " 33880    1991-92\n",
       " 33881    1992-93\n",
       " 33882    1993-94\n",
       " 33883    1994-95\n",
       " 33884    1995-96\n",
       " 33885    1996-97\n",
       " 33886    1996-97\n",
       " 33887    1996-97\n",
       " 33888    1997-98\n",
       " 33889    1998-99\n",
       " 33890    1999-00\n",
       " 33891    2000-01\n",
       " 33892     Career\n",
       " Name: Season, Length: 33893, dtype: object, 0        1.0\n",
       " 1        0.0\n",
       " 2        0.0\n",
       " 3        0.0\n",
       " 4        0.0\n",
       " 5        0.0\n",
       " 6        0.0\n",
       " 7        0.0\n",
       " 8        0.0\n",
       " 9        0.0\n",
       " 10       0.0\n",
       " 11       0.0\n",
       " 12       0.0\n",
       " 13       0.0\n",
       " 14       0.0\n",
       " 15       0.0\n",
       " 16       0.0\n",
       " 17       0.0\n",
       " 18       0.0\n",
       " 19       0.0\n",
       " 20       0.0\n",
       " 21       0.0\n",
       " 22       0.0\n",
       " 23       0.0\n",
       " 24       0.0\n",
       " 25       0.0\n",
       " 26       0.0\n",
       " 27       0.0\n",
       " 28       0.0\n",
       " 29       0.0\n",
       "         ... \n",
       " 33863    0.0\n",
       " 33864    0.0\n",
       " 33865    0.0\n",
       " 33866    0.0\n",
       " 33867    0.0\n",
       " 33868    0.0\n",
       " 33869    0.0\n",
       " 33870    0.0\n",
       " 33871    0.0\n",
       " 33872    0.0\n",
       " 33873    0.0\n",
       " 33874    0.0\n",
       " 33875    0.0\n",
       " 33876    0.0\n",
       " 33877    1.0\n",
       " 33878    0.0\n",
       " 33879    0.0\n",
       " 33880    0.0\n",
       " 33881    0.0\n",
       " 33882    0.0\n",
       " 33883    0.0\n",
       " 33884    0.0\n",
       " 33885    0.0\n",
       " 33886    0.0\n",
       " 33887    0.0\n",
       " 33888    0.0\n",
       " 33889    0.0\n",
       " 33890    0.0\n",
       " 33891    0.0\n",
       " 33892    0.0\n",
       " Name: 當年度獎項次數, Length: 33893, dtype: float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ss['Season'] , ss['當年度獎項次數'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
